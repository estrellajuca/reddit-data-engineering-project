<h1>2021 Olympics ETL Pipeline using Microsoft Azure Services</h1>


<h2>Description</h2>
In this project, I developed a data pipeline to process and analyze data from the 2021 Tokyo Olympics using Azure's cloud ecosystem. 
The pipeline involved ingesting raw data into Azure DataLake Storage Gen2 with Data Factory, transforming it with PySpark in Azure Databricks, and storing the processed data in the same Datalake. 
Then Azure Synapse Analytics was used for efficient querying and analysis. 
<br />


<h2>Languages and Utilities Used</h2>

- <b>Python</b> 
- <b>Airflow</b>
- <b>Docker</b>
- <b>AWS Glue</b>
- <b>AWS S3</b>
- <b>AWS Athena</b>
- <b>AWS Redshift</b>

<h2>Project walk-through:</h2>

<h3>Pipeline Flow:</h3>
<img src="https://i.imgur.com/nLKI0ui.png" height="80%" width="80%" />
<br />
<br />


<!--
 ```diff
- text in red
+ text in green
! text in orange
# text in gray
@@ text in purple (and bold)@@
```
--!>
